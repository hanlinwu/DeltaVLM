# Training Configuration for DeltaVLM Stage 2 (Instruction Tuning)
# Usage: python scripts/train.py --cfg_path configs/train_stage2.yaml

model:
  arch: "instruct_vicuna7b"
  model_type: "vicuna7b"
  
  # NOTE: Set this to your Stage 1 checkpoint path, or remove if training from scratch
  # pretrained: "./pretrained/deltavlm_stage1.pth"
  
  vit_model: "eva_clip_g"
  image_size: 224
  drop_path_rate: 0
  use_grad_checkpoint: false
  vit_precision: "fp16"
  freeze_vit: true
  
  num_query_token: 32
  qformer_text_input: true
  
  llm_model: "lmsys/vicuna-7b-v1.5"
  
  prompt: ""
  max_txt_len: 128
  max_output_txt_len: 256
  apply_lemmatizer: false

datasets:
  changechat:
    type: default
    
    vis_processor:
      train:
        name: blip2_image_train
        image_size: 224
        min_scale: 0.5
        max_scale: 1.0
      eval:
        name: blip_image_eval
        image_size: 224
        
    text_processor:
      train:
        name: blip_caption
        prompt: ""
        max_words: 50
      eval:
        name: blip_caption
        prompt: ""
        max_words: 50
    
    # NOTE: Update these paths to your local dataset location
    # See docs/DATA.md for dataset download and structure
    build_info:
      annotations:
        train:
          storage: "data/changechat/annotations/train.json"
        val:
          storage: "data/changechat/annotations/val.json"
        test:
          storage: "data/changechat/annotations/test.json"
      images:
        storage: "data/changechat/images"

run:
  task: image_text_pretrain
  
  lr_sched: linear_warmup_cosine_lr
  init_lr: 1e-5
  min_lr: 1e-6
  warmup_lr: 1e-7
  warmup_steps: 500
  weight_decay: 0.05
  
  max_epoch: 30
  batch_size_train: 24
  batch_size_eval: 16
  num_workers: 4
  accum_grad_iters: 1
  
  val_freq: 1
  stop_criteria: 5
  
  save_freq: 5
  save_last: true
  output_dir: "output/stage2"
  
  evaluate: false
  train_splits: ["train"]
  valid_splits: ["val"]
  test_splits: ["test"]
  
  device: cuda
  seed: 42
  distributed: false
  amp: true
